Hello again, as stated in my thesis, my research on eye gaze started with the original mpii-gaze paper and sample code (available here): https://www.mpi-inf.mpg.de/de/abteilungen/computer-vision-and-multimodal-computing/research/gaze-based-human-computer-interaction/appearance-based-gaze-estimation-in-the-wild-mpiigaze/

The key result of my paper is that if the left and right eye is fed into the network at the same time (for example the left eye crop in channel 0 and the right eye crop in channel 1) and the gaze vector merged, the results improved. This is like simulating treating the two eyes as if they were one eye located directly above the nose but looking at the same object.  

When I was doing this research I was not expecting to find better results nor did I expect to write a paper about it. I actually wrote the paper about 5 months after the research was finished using my "weekly reports" as source material. As such, not everything is easy to find and some of the code is very hastily written and may need modification in line with what is written in the paper in order to work properly. 

Unfortunately you will have no documentation because I didn't make any. I apologize. I know it's not fun to figure out someone else’s undocumented research code. I hope it helps you nonetheless. 
I would send you the directory that contains every experiment, every model, and all the data but unfortunately it is too large to send (several gigabytes). As such, I've made a directory with just the source files that you'll need to duplicate some of the experiments in the paper. 

The first step is to recompile caffe with the modified accuracy and Euclidian loss layers.I modified these layers from the ones provided by the author of the original mpiigaze paper to prevent NAN loss coming from use of acos on values <= -1.0 or >= 1. This seemed to make training more stable. 

You can find them in: CaffeLayerModification/modifications/euclidean_loss_layer.cpp
and CaffeLayerModification/modifications/accuracy_layer.cpp
As I mentioned in the paper, there were several ways of generating the data. You can see most of the various data generation scripts in  gaze/mpiigaze/ with names such as generatedata.py, generatedata2.py, make2channel.py, make2channelrflip.py, make2channelwaug.py, newdb.py, resolutionaccuracyflipr.py, resolutionaccuracy.py 
Many of these will generate several mdf5 files with a .m5 extension. These are in turn used by the train.txt and test.txt files. 

We generate a different mdf5 file for each individual in the dataset. 

To train the network you need:
0. The original mpii-gaze dataset, processed with one of the scripts mentioned earlier. 
1. A prototxt file implementing the network 
2. A solver file
3. A train.txt file
4. A test.txt file

The gaze/mpiigaze/trainingcode directory contains the caffe training code required to train the last network mentioned in the paper. You'll need to adjust the paths to suit your machine. 

train.txt and test.txt contain the paths of the training and testing datasets (the mdf5 files generated by the dataset generation scripts).
